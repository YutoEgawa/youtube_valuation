import streamlit as st
import pandas as pd
import re
from datetime import datetime
import numpy as np
import math
import urllib.parse
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload
import io

# ğŸŒ Language switcher
language = st.radio("ğŸŒ Select Language / è¨€èªã‚’é¸ã‚“ã§ãã ã•ã„", ("Japanese", "English"))

labels = {
    "Japanese": {
        "title": "YouTube Channelè³‡ç”£ä¾¡å€¤æŸ»å®š",
        "channelname": "ãƒãƒ£ãƒ³ãƒãƒ«åï¼ˆä»»æ„ï¼‰",
        "upload": "æœˆåˆ¥ãƒ»å‹•ç”»åˆ¥ã®å†ç”Ÿå›æ•°ã‚’CSVå½¢å¼ã§ã”è‡ªèº«ã®Youtube Studioã‹ã‚‰å–å¾—ã—ä»¥ä¸‹ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        "short_result": "shortå‹•ç”»åˆ†é¡å¾Œã®ãƒ‡ãƒ¼ã‚¿",
        "future_views": "å°†æ¥ã®å†ç”Ÿå›æ•°ï¼ˆäºˆæ¸¬ï¼‰ä»˜ããƒ‡ãƒ¼ã‚¿",
        "value_table": "DCFè³‡ç”£ä¾¡å€¤ï¼ˆå‹•ç”»å˜ä½ï¼‰",
        "channel_value": "ğŸ“ˆ ãƒãƒ£ãƒ³ãƒãƒ«å…¨ä½“ã®è³‡ç”£ä¾¡å€¤ï¼š{:,} å††",
        "share": "ğŸ•Š Xã§ã‚·ã‚§ã‚¢ã™ã‚‹ï¼ˆæ—§Twitterï¼‰",
        "download": "ğŸ’¾ å‹•ç”»ã”ã¨ã®è³‡ç”£ä¾¡å€¤ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        "tweet_text": "ç§ã®YouTubeãƒãƒ£ãƒ³ãƒãƒ«ã®è³‡ç”£ä¾¡å€¤ã¯ {:,} å††ã§ã—ãŸï¼ğŸ“ˆ\n\n#YouTube #è³‡ç”£ä¾¡å€¤ #å‹•ç”»åˆ†æ",
        "contact":"ğŸ“© ã”ä¸æ˜ç‚¹ãŒã‚ã‚Œã° [your-email@example.com](mailto:your-email@example.com) ã¾ã§ãŠæ°—è»½ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚",
        "privacy_policy": "ğŸ”å½“ã‚¢ãƒ—ãƒªã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã®ãŸã‚ã«ä¸€æ™‚çš„ã«ä½¿ç”¨ã—ã¾ã™ã€‚\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åŒæ„ãªã—ã«ã€æƒ…å ±ã‚’ç¬¬ä¸‰è€…ãŒé–²è¦§ã§ãã‚‹çŠ¶æ…‹ã«ç½®ãã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"   
    },
    "English": {
        "title": "YouTube Channel Asset Valuation App",
        "channelname": "Channel Name (optional)",
        "upload": "Upload your monthly view-counts by video downloadable from your YouTube Studio",
        "short_result": "Short Video Classification Result",
        "future_views": "Future Monthly Views (Projected)",
        "value_table": "DCF Asset Value per Video",
        "channel_value": "ğŸ“ˆ Total Channel Asset Value: Â¥{:,}",
        "share": "ğŸ•Š Share on X (Twitter)",
        "download": "ğŸ’¾ Download CSV of Asset Value per Video",
        "tweet_text": "My YouTube channel is worth Â¥{:,}! ğŸ“ˆ\n\n#YouTube #AssetValuation #CreatorEconomy",
        "contact":"ğŸ“© Contact us: [your-email@example.com](mailto:your-email@example.com)" ,
        "privacy_policy":" ğŸ”This app uses uploaded CSV files only for processing purposes. No data will be shared externally without consent." 
    }
}

text = labels[language]

st.title(text["title"])

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰éƒ¨åˆ†
uploaded_files = st.file_uploader(
    text["upload"],
    type="csv",
    accept_multiple_files=True
)

# æ—¥æœ¬èªâ†’è‹±èªã¸ã®ã‚«ãƒ©ãƒ åå¤‰æ›ãƒãƒƒãƒ—ï¼ˆå¿…è¦ãªåˆ†ã ã‘ï¼‰
rename_dict = {
    'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„': 'videoId',
    'å‹•ç”»ã®ã‚¿ã‚¤ãƒˆãƒ«': 'title',
    'å‹•ç”»å…¬é–‹æ™‚åˆ»': 'publishedAt',
    'é•·ã•': 'duration',
    'è¦–è´å›æ•°': 'viewCount',
    'æ–°ã—ã„è¦–è´è€…æ•°': 'newViewers',
    'ç™»éŒ²è€…å¢—åŠ æ•°': 'subscriberGain',
}

# ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å¹´æœˆã‚’æŠ½å‡º
def extract_year_month(filename):
    match = re.search(r"(\d{4})[^\d]?(\d{2})", filename)
    if match:
        return match.group(1), match.group(2)
    return None, None

# CSVã‚’å‡¦ç†ã™ã‚‹é–¢æ•°
def process_csv(file):
    df = pd.read_csv(file)
    df.rename(columns=rename_dict, inplace=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å¹´æœˆå–å¾—
    year, month = extract_year_month(file.name)
    if not year or not month:
        st.warning(f"{file.name} ã‹ã‚‰å¹´æœˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return None

    # åˆè¨ˆè¡Œã¯é™¤å¤–
    df = df[df["videoId"] != "åˆè¨ˆ"]

    # å¿…è¦ãªã‚«ãƒ©ãƒ ã ã‘æ®‹ã™
    df = df[['videoId', 'title', 'publishedAt', 'duration', 'viewCount', 'newViewers', 'subscriberGain']]

    # ã‚«ãƒ©ãƒ åã‚’å¹´æœˆä»˜ãã«å¤‰æ›´
    df.rename(columns={
        'viewCount': f'viewCount_{year}_{month}',
        'newViewers': f'newViewers_{year}_{month}',
        'subscriberGain': f'subscriberGain_{year}_{month}',
    }, inplace=True)

    return df


# å…¬é–‹æ—¥ã¨å‹•ç”»æ™‚é–“ã‚’ã‚‚ã¨ã«shortã‚’åˆ¤å®š
def classify_short_videos(df):
    cutoff_date = datetime(2024, 10, 15)

    def is_short(row):
        if pd.isna(row['publishedAt']) or pd.isna(row['duration']):
            return 0

        try:
            duration_sec = float(row['duration'])
        except ValueError:
            return 0

        # å…¬é–‹æ—¥ãŒéå»ã‹æœªæ¥ã‹ã§åŸºæº–ãŒå¤‰ã‚ã‚‹
        pub_date = pd.to_datetime(row['publishedAt'], errors='coerce')
        if pd.isna(pub_date):
            return 0

        if pub_date < cutoff_date:
            return 1 if duration_sec <= 60 else 0
        else:
            return 1 if duration_sec <= 179 else 0

    df['short'] = df.apply(is_short, axis=1)
    return df

def project_future_views(df, growth_factors=(0.5, 0.4, 0.3)):
    # æœˆåˆ¥å†ç”Ÿå›æ•°ã‚«ãƒ©ãƒ ã‚’æŠ½å‡º
    view_cols = [col for col in df.columns if col.startswith("viewCount_") and not col.endswith("E")]
    view_cols_sorted = sorted(view_cols)

    # æœ€çµ‚æœˆã‚’å–å¾—
    latest_col = view_cols_sorted[-1]
    latest_date_str = latest_col.replace("viewCount_", "")  # '2024_10'
    latest_date = pd.to_datetime(latest_date_str, format="%Y_%m")

    for i, factor in enumerate(growth_factors, start=1):
        future_date = latest_date + pd.DateOffset(months=i)
        future_col = f"viewCount_{future_date.strftime('%Y_%m')}E"

        df[future_col] = df[latest_col] * factor

    return df

def compute_dcf(df, revenue_per_view=0.5, discount_rate=0.1, terminal_multiple=12):
    future_cols = [col for col in df.columns if col.endswith("E")]
    future_cols = sorted(future_cols)

    monthly_discount = math.pow(1 + discount_rate, 1/12) - 1

    for i, col in enumerate(future_cols):
        dcf_col = f"dcf_{col}"
        df[dcf_col] = (df[col] * revenue_per_view) / ((1 + monthly_discount) ** (i + 1))

    if future_cols:
        last_col = future_cols[-1]
        df["terminal_views"] = df[last_col] * terminal_multiple
        df["dcf_terminal"] = (df["terminal_views"] * revenue_per_view) / ((1 + monthly_discount) ** len(future_cols))

    dcf_cols = [col for col in df.columns if col.startswith("dcf_")]
    df["total_dcf_value"] = df[dcf_cols].sum(axis=1)

    return df

def upload_csv_to_drive(file, username="anonymous"):
    SCOPES = ['https://www.googleapis.com/auth/drive.file']
    creds = service_account.Credentials.from_service_account_file(
        "credentials.json", scopes=SCOPES
    )
    service = build('drive', 'v3', credentials=creds)

    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{username}_{timestamp}_{file.name}"

    file_data = io.BytesIO(file.getvalue())
    media = MediaIoBaseUpload(file_data, mimetype='text/csv')

    # ğŸ”½ ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€IDã‚’æŒ‡å®šï¼ˆã“ã“ã‚’å¤‰æ›´ï¼‰
    file_metadata = {
        'name': filename,
        'parents': ['1QiQ9s9xj3rCBbNBBauxSTP8sLKogHT1o']  # â† ã‚ãªãŸã®ãƒ•ã‚©ãƒ«ãƒ€IDã«ç½®ãæ›ãˆ
    }

    uploaded = service.files().create(
        body=file_metadata,
        media_body=media,
        fields='id'
    ).execute()

    return uploaded.get('id')

username = st.text_input(text["channelname"], value="blank")

if uploaded_files:
    dfs = []
    for file in uploaded_files:
        file_id = upload_csv_to_drive(file, username)
        st.success(f"âœ… {file.name} ã‚’Google Driveã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼ˆID: {file_id}ï¼‰")
        df = process_csv(file)
        if df is not None:
            dfs.append(df)

    if dfs:
        df_merged = dfs[0]
        for df in dfs[1:]:
            df_merged = pd.merge(df_merged, df, on=['videoId', 'title', 'publishedAt', 'duration'], how='outer')

        # ğŸ”¥ shortåˆ†é¡ã®å®Ÿè¡Œ
        df_merged = classify_short_videos(df_merged)

        # ğŸ”® å°†æ¥3ã‹æœˆåˆ†ã®å†ç”Ÿå›æ•°ã‚’äºˆæ¸¬
        df_merged = project_future_views(df_merged)

        # ğŸ’° DCFã§å‹•ç”»ã”ã¨ã®ä¾¡å€¤ã‚’ç®—å‡º
        df_merged = compute_dcf(df_merged)

        st.subheader(text["value_table"])
        st.dataframe(df_merged[['videoId', 'title', 'total_dcf_value']].sort_values(by='total_dcf_value', ascending=False).head(10))

        # ğŸ“Š ãƒãƒ£ãƒ³ãƒãƒ«å…¨ä½“ã®è³‡ç”£ä¾¡å€¤
        total_channel_value = df_merged["total_dcf_value"].sum()
        st.success(text["channel_value"].format(round(total_channel_value)))

        # ğŸ•Š Xã§ã‚·ã‚§ã‚¢ã™ã‚‹ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤º
        tweet_text = text["tweet_text"].format(total_channel_value)
        tweet_url = "https://twitter.com/intent/tweet?text=" + urllib.parse.quote(tweet_text)
        st.markdown(f"[{text['share']}]({tweet_url})", unsafe_allow_html=True)

        # ğŸ’¾ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®CSVã‚’ä½œæˆ
        csv = df_merged[['videoId', 'title', 'total_dcf_value']].to_csv(index=False).encode('utf-8')
        st.download_button(
            label=text["download"],
            data=csv,
            file_name='youtube_asset_valuation.csv',
            mime='text/csv'
        )

st.markdown("---")
st.markdown(text["contact"], unsafe_allow_html=True)

st.markdown(text["privacy_policy"])
